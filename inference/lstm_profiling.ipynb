{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\29197\\miniconda3\\envs\\566_new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "# y = None\n",
    "embed_size = 96\n",
    "\n",
    "# backbone = torchvision.models.resnet18(num_classes = embed_size)\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self, backbone,embed_size = embed_size, in_between = 64, out_features = 4, num_layers = 2, bidirectional = False):\n",
    "        super(lstm, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.backbone = backbone\n",
    "        # self.embedding = nn.Embedding(x_grid_size * y_grid_size + 1, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size = embed_size, hidden_size = 300, batch_first = True, bidirectional = bidirectional, dropout = 0.1, num_layers = num_layers)\n",
    "        # self.rnn2 = nn.LSTM(input_size = embed_size, hidden_size = 100, batch_first = True, bidirectional = True, dropout = 0.1, num_layers = num_layers)\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(300, 200)\n",
    "        self.dropout2 = nn.Dropout(p = 0.1)\n",
    "        self.fc2 = nn.Linear(200, 5)\n",
    "\n",
    "\n",
    "        # self.keypoint_head_1 = nn.Linear(in_features=embed_size, out_features=in_between)\n",
    "        # self.keypoint_head_2 = nn.Linear(in_features=in_between, out_features = out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.rnn(x)[1][0].shape)\n",
    "        # return self.fc(torch.squeeze(self.rnn(x)[1][0], dim=0))\n",
    "        # print(self.rnn(x)[0].shape)\n",
    "        # global y\n",
    "        # y = x\n",
    "        a, b, c, d, e = x.shape\n",
    "        features = self.backbone(x.view((a * b, c, d, e))).view((a, b, self.embed_size))\n",
    "        return self.fc2(self.dropout2(self.relu( \\\n",
    "            self.fc1(self.dropout(self.rnn(features)[0][:, -1, :])))))\n",
    "         # self.keypoint_head_2(nn.ReLU()(self.keypoint_head_1(features.view((a * b, self.embed_size)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = lstm(backbone=torchvision.models.resnet18(num_classes = embed_size)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstm(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=96, bias=True)\n",
       "  )\n",
       "  (rnn): LSTM(96, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (fc1): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=200, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = '../resnet_with_regression_and_cls_4_12.pt'\n",
    "model.load_state_dict(torch.load(MODEL_PATH), strict= False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         77403 function calls (68903 primitive calls) in 1.900 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      100    0.005    0.000    1.886    0.019 1973413933.py:29(forward)\n",
      "        1    0.014    0.014    1.900    1.900 <string>:1(<module>)\n",
      "      300    0.000    0.000    0.000    0.000 _VF.py:26(__getattr__)\n",
      "     2000    0.001    0.000    0.001    0.000 __init__.py:31(__get__)\n",
      "      100    0.000    0.000    0.028    0.000 _jit_internal.py:475(fn)\n",
      "     1700    0.002    0.000    0.158    0.000 activation.py:101(forward)\n",
      "      100    0.000    0.000    0.004    0.000 activation.py:774(forward)\n",
      "     2000    0.010    0.000    0.139    0.000 batchnorm.py:137(forward)\n",
      "     2000    0.002    0.000    0.003    0.000 batchnorm.py:408(_check_input_dim)\n",
      "      700    0.001    0.000    0.001    0.000 container.py:194(__iter__)\n",
      "  700/400    0.003    0.000    0.781    0.002 container.py:202(forward)\n",
      "     2000    0.003    0.000    1.248    0.001 conv.py:454(_conv_forward)\n",
      "     2000    0.004    0.000    1.254    0.001 conv.py:462(forward)\n",
      "      200    0.000    0.000    0.002    0.000 dropout.py:58(forward)\n",
      "      100    0.000    0.000    0.006    0.000 functional.py:1200(adaptive_avg_pool2d)\n",
      "      200    0.001    0.000    0.002    0.000 functional.py:1235(dropout)\n",
      "     1700    0.002    0.000    0.156    0.000 functional.py:1446(relu)\n",
      "      100    0.000    0.000    0.004    0.000 functional.py:1618(leaky_relu)\n",
      "     2000    0.005    0.000    0.121    0.000 functional.py:2419(batch_norm)\n",
      "      100    0.000    0.000    0.028    0.000 functional.py:760(_max_pool2d)\n",
      "      300    0.001    0.000    0.033    0.000 linear.py:113(forward)\n",
      " 8300/100    0.022    0.000    1.887    0.019 module.py:1188(_call_impl)\n",
      "    21700    0.014    0.000    0.014    0.000 module.py:1256(__getattr__)\n",
      "      100    0.000    0.000    0.006    0.000 pooling.py:1183(forward)\n",
      "      100    0.000    0.000    0.029    0.000 pooling.py:165(forward)\n",
      "      100    0.003    0.000    1.680    0.017 resnet.py:266(_forward_impl)\n",
      "      100    0.000    0.000    1.680    0.017 resnet.py:284(forward)\n",
      "      800    0.037    0.000    0.774    0.001 resnet.py:89(forward)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:203(check_input)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:214(get_expected_hidden_size)\n",
      "      200    0.000    0.000    0.000    0.000 rnn.py:228(check_hidden_size)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:680(get_expected_cell_size)\n",
      "      100    0.000    0.000    0.001    0.000 rnn.py:692(check_forward_args)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:704(permute_hidden)\n",
      "      100    0.002    0.000    0.167    0.002 rnn.py:726(forward)\n",
      "      100    0.001    0.000    0.001    0.000 utils.py:32(_list_with_default)\n",
      "      100    0.000    0.000    0.000    0.000 utils.py:39(<listcomp>)\n",
      "        1    0.000    0.000    1.900    1.900 {built-in method builtins.exec}\n",
      "      300    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      300    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "      700    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "      300    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "     2000    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "     8300    0.011    0.000    0.011    0.000 {built-in method torch._C._get_tracing_state}\n",
      "     2200    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "     2000    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}\n",
      "      100    0.004    0.000    0.004    0.000 {built-in method torch._C._nn.leaky_relu}\n",
      "      300    0.032    0.000    0.032    0.000 {built-in method torch._C._nn.linear}\n",
      "     2000    0.115    0.000    0.115    0.000 {built-in method torch.batch_norm}\n",
      "     2000    1.245    0.001    1.245    0.001 {built-in method torch.conv2d}\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method torch.dropout}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch.flatten}\n",
      "      100    0.158    0.002    0.158    0.002 {built-in method torch.lstm}\n",
      "      100    0.028    0.000    0.028    0.000 {built-in method torch.max_pool2d}\n",
      "     1700    0.154    0.000    0.154    0.000 {built-in method torch.relu_}\n",
      "      200    0.006    0.000    0.006    0.000 {built-in method torch.zeros}\n",
      "     2200    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      700    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "      700    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "      200    0.002    0.000    0.002    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "input = torch.zeros(size=(1, 16, 3, 224, 224), device= device)\n",
    "with torch.no_grad():\n",
    "    cProfile.run('for i in range(100): \\n    model(input)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class fast_inference(nn.Module):\n",
    "    def __init__(self, backbone,embed_size = embed_size, in_between = 64, out_features = 4, num_layers = 2, num_frame = 16, bidirectional = False):\n",
    "        super(fast_inference, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.backbone = backbone\n",
    "        # self.embedding = nn.Embedding(x_grid_size * y_grid_size + 1, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size = embed_size, hidden_size = 300, batch_first = True, bidirectional = bidirectional, dropout = 0.1, num_layers = num_layers)\n",
    "        # self.rnn2 = nn.LSTM(input_size = embed_size, hidden_size = 100, batch_first = True, bidirectional = True, dropout = 0.1, num_layers = num_layers)\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(300, 200)\n",
    "        self.dropout2 = nn.Dropout(p = 0.1)\n",
    "        self.fc2 = nn.Linear(200, 5)\n",
    "\n",
    "        self.features = torch.zeros(size=(num_frame, embed_size), device = device)\n",
    "        self.num_frame = num_frame\n",
    "\n",
    "\n",
    "        # self.keypoint_head_1 = nn.Linear(in_features=embed_size, out_features=in_between)\n",
    "        # self.keypoint_head_2 = nn.Linear(in_features=in_between, out_features = out_features)\n",
    "\n",
    "        # self.training = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.rnn(x)[1][0].shape)\n",
    "        # return self.fc(torch.squeeze(self.rnn(x)[1][0], dim=0))\n",
    "        # print(self.rnn(x)[0].shape)\n",
    "        # global y\n",
    "        # y = x\n",
    "        o = self.backbone(x)\n",
    "        \n",
    "        self.features = torch.concat((self.features[1:,:], o))\n",
    "        \n",
    "        # print(self.features.shape)\n",
    "        \n",
    "        return self.fc2(self.dropout2(self.relu( \\\n",
    "            self.fc1(self.dropout(self.rnn(self.features)[0][-1, :])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fast_inference(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=96, bias=True)\n",
       "  )\n",
       "  (rnn): LSTM(96, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (fc1): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=200, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_model = fast_inference(backbone=torchvision.models.resnet18(num_classes = embed_size)).to(device)\n",
    "fast_model.load_state_dict(torch.load(MODEL_PATH), strict= False)\n",
    "fast_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_model(torch.zeros(size=(1, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         78703 function calls (70103 primitive calls) in 0.912 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      100    0.007    0.000    0.908    0.009 1150694688.py:24(forward)\n",
      "        1    0.003    0.003    0.912    0.912 <string>:1(<module>)\n",
      "      300    0.000    0.000    0.000    0.000 _VF.py:26(__getattr__)\n",
      "     2000    0.001    0.000    0.001    0.000 __init__.py:31(__get__)\n",
      "      100    0.000    0.000    0.009    0.000 _jit_internal.py:475(fn)\n",
      "     1700    0.003    0.000    0.049    0.000 activation.py:101(forward)\n",
      "      100    0.000    0.000    0.004    0.000 activation.py:774(forward)\n",
      "     2000    0.012    0.000    0.192    0.000 batchnorm.py:137(forward)\n",
      "     2000    0.003    0.000    0.004    0.000 batchnorm.py:408(_check_input_dim)\n",
      "      700    0.001    0.000    0.001    0.000 container.py:194(__iter__)\n",
      "  700/400    0.003    0.000    0.677    0.002 container.py:202(forward)\n",
      "     2000    0.003    0.000    0.365    0.000 conv.py:454(_conv_forward)\n",
      "     2000    0.006    0.000    0.373    0.000 conv.py:462(forward)\n",
      "      200    0.000    0.000    0.003    0.000 dropout.py:58(forward)\n",
      "      100    0.001    0.000    0.006    0.000 functional.py:1200(adaptive_avg_pool2d)\n",
      "      200    0.001    0.000    0.002    0.000 functional.py:1235(dropout)\n",
      "     1700    0.002    0.000    0.047    0.000 functional.py:1446(relu)\n",
      "      100    0.000    0.000    0.004    0.000 functional.py:1618(leaky_relu)\n",
      "     2000    0.005    0.000    0.171    0.000 functional.py:2419(batch_norm)\n",
      "      100    0.000    0.000    0.008    0.000 functional.py:760(_max_pool2d)\n",
      "      300    0.001    0.000    0.033    0.000 linear.py:113(forward)\n",
      " 8300/100    0.026    0.000    0.909    0.009 module.py:1188(_call_impl)\n",
      "    21700    0.016    0.000    0.016    0.000 module.py:1256(__getattr__)\n",
      "      100    0.001    0.000    0.002    0.000 module.py:1272(__setattr__)\n",
      "      100    0.001    0.000    0.001    0.000 parameter.py:8(__instancecheck__)\n",
      "      100    0.000    0.000    0.007    0.000 pooling.py:1183(forward)\n",
      "      100    0.001    0.000    0.009    0.000 pooling.py:165(forward)\n",
      "      100    0.004    0.000    0.738    0.007 resnet.py:266(_forward_impl)\n",
      "      100    0.000    0.000    0.739    0.007 resnet.py:284(forward)\n",
      "      800    0.040    0.000    0.669    0.001 resnet.py:89(forward)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:203(check_input)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:214(get_expected_hidden_size)\n",
      "      200    0.000    0.000    0.000    0.000 rnn.py:228(check_hidden_size)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:680(get_expected_cell_size)\n",
      "      100    0.001    0.000    0.002    0.000 rnn.py:692(check_forward_args)\n",
      "      100    0.000    0.000    0.000    0.000 rnn.py:704(permute_hidden)\n",
      "      100    0.002    0.000    0.122    0.001 rnn.py:726(forward)\n",
      "      100    0.001    0.000    0.001    0.000 utils.py:32(_list_with_default)\n",
      "      100    0.000    0.000    0.000    0.000 utils.py:39(<listcomp>)\n",
      "        1    0.000    0.000    0.912    0.912 {built-in method builtins.exec}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "  600/500    0.000    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      700    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "      300    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "     2000    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "     8300    0.016    0.000    0.016    0.000 {built-in method torch._C._get_tracing_state}\n",
      "     2200    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "     2000    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "      100    0.005    0.000    0.005    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method torch._C._nn.leaky_relu}\n",
      "      300    0.032    0.000    0.032    0.000 {built-in method torch._C._nn.linear}\n",
      "     2000    0.164    0.000    0.164    0.000 {built-in method torch.batch_norm}\n",
      "      100    0.007    0.000    0.007    0.000 {built-in method torch.concat}\n",
      "     2000    0.362    0.000    0.362    0.000 {built-in method torch.conv2d}\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method torch.dropout}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method torch.flatten}\n",
      "      100    0.105    0.001    0.105    0.001 {built-in method torch.lstm}\n",
      "      100    0.008    0.000    0.008    0.000 {built-in method torch.max_pool2d}\n",
      "     1700    0.044    0.000    0.044    0.000 {built-in method torch.relu_}\n",
      "      200    0.006    0.000    0.006    0.000 {built-in method torch.zeros}\n",
      "      100    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x000001D0A9F0CCA0}\n",
      "     2200    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      300    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      700    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "      300    0.003    0.000    0.003    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
      "      700    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = torch.zeros(size=(1, 3, 224, 224), device=device)\n",
    "with torch.no_grad():\n",
    "    cProfile.run('for i in range(100): \\n    fast_model(input)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1757,  0.1765, -0.5562,  0.0133, -0.0063], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1758,  0.1764, -0.5562,  0.0133, -0.0063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 16, 3, 224, 224).to(device)\n",
    "\n",
    "output1 = model(input)\n",
    "\n",
    "for i in range(16):\n",
    "    output2 = fast_model(input[:, i, :, :, :])\n",
    "\n",
    "print(output2)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_model.rnn(torch.zeros(size=(16, 96)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_model.rnn(torch.zeros(size=(16, 96)))[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_model.rnn(torch.zeros(size=(1, 96)))[0][-1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_model.rnn(torch.zeros(size=(1, 96)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "FLOPs = 29.196472904G\n",
      "Params = 12.486965M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "input = torch.randn(1, 16, 3, 224, 224).to(device)\n",
    "flops, params = profile(model, inputs = (input, ))\n",
    "\n",
    "print('FLOPs = ' + str(flops/1000**3) + 'G')\n",
    "print('Params = ' + str(params/1000**2) + 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "FLOPs = 3.674204744G\n",
      "Params = 12.486965M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "input = torch.randn(1, 3, 224, 224).to(device)\n",
    "flops, params = profile(fast_model, inputs=(input, ))\n",
    "\n",
    "print('FLOPs = ' + str(flops/1000**3) + 'G')\n",
    "print('Params = ' + str(params/1000**2) + 'M')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "566_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
